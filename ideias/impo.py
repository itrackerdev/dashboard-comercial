import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import hashlib
import os

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="Dashboard de Oportunidades Comerciais",
    page_icon="ðŸš¢",
    layout="wide"
)

def create_unique_id(row):
    """Cria um ID Ãºnico para cada registro baseado em campos chave"""
    # Combinando campos relevantes para criar uma chave Ãºnica
    unique_string = f"{row['EMBARQUE']}_{row['CONSIGNATÃRIO']}_{row['ETA']}_{row['PORTO DESTINO']}_{row['CONTAINER PARCIAL']}_{row['VIAGEM']}"
    # Criando um hash do string para ter um ID Ãºnico
    return hashlib.md5(unique_string.encode()).hexdigest()

def remove_duplicates(df):
    """Remove registros duplicados mantendo apenas a versÃ£o mais recente"""
    # Criando ID Ãºnico para cada registro
    df['ID_UNICO'] = df.apply(create_unique_id, axis=1)
    
    # Adicionando data de atualizaÃ§Ã£o
    df['DATA_ATUALIZACAO'] = datetime.now()
    
    # Se existe um arquivo de dados consolidados, carregar
    if os.path.exists('dados_consolidados.parquet'):
        df_consolidated = pd.read_parquet('dados_consolidados.parquet')
        
        # Combinando dados antigos com novos, mantendo apenas os mais recentes
        df_all = pd.concat([df_consolidated, df])
        df_all = df_all.sort_values('DATA_ATUALIZACAO').drop_duplicates(
            subset=['ID_UNICO'], 
            keep='last'
        )
    else:
        df_all = df
    
    # Salvando dados consolidados
    df_all.to_parquet('dados_consolidados.parquet')
    
    # Registrando log de atualizaÃ§Ã£o
    with open('log_atualizacao.txt', 'a') as f:
        f.write(f"{datetime.now()} - Registros processados: {len(df)}, "
                f"Registros Ãºnicos apÃ³s processamento: {len(df_all)}\n")
    
    return df_all

def load_data():
    """Carrega e processa os dados do Excel"""
    try:
        # Lendo o arquivo Excel
        df = pd.read_excel('ImportaÃ§Ã£o.xlsx')
        
        # Convertendo datas
        df['ETA'] = pd.to_datetime(df['ETA'], format='%d/%m/%Y')
        
        # Convertendo QTDE CONTAINER para numÃ©rico
        df['QTDE CONTAINER'] = df['QTDE CONTAINER'].str.replace(',', '.').astype(float)
        
        # Removendo duplicidades
        df = remove_duplicates(df)
        
        return df
        
    except Exception as e:
        st.error(f"Erro ao carregar os dados: {str(e)}")
        return None

def show_update_info():
    """Exibe informaÃ§Ãµes sobre as atualizaÃ§Ãµes dos dados"""
    if os.path.exists('log_atualizacao.txt'):
        with open('log_atualizacao.txt', 'r') as f:
            last_updates = f.readlines()[-5:]  # Mostra as Ãºltimas 5 atualizaÃ§Ãµes
        
        st.sidebar.markdown("### â±ï¸ Ãšltimas AtualizaÃ§Ãµes")
        for update in last_updates:
            st.sidebar.text(update.strip())

def main():
    st.title("ðŸ“Š Dashboard de Oportunidades Comerciais")
    st.markdown("### AnÃ¡lise de ImportaÃ§Ãµes e Oportunidades de NegÃ³cio")

    # Adicionando informaÃ§Ãµes de atualizaÃ§Ã£o na sidebar
    show_update_info()

    try:
        # Carregando os dados
        df = load_data()
        
        if df is None:
            st.error("NÃ£o foi possÃ­vel carregar os dados.")
            return

        # Exibindo Ãºltima atualizaÃ§Ã£o
        st.sidebar.markdown(f"### ðŸ”„ Status dos Dados")
        st.sidebar.markdown(f"Ãšltima atualizaÃ§Ã£o: {df['DATA_ATUALIZACAO'].max().strftime('%d/%m/%Y %H:%M')}")
        st.sidebar.markdown(f"Total de registros Ãºnicos: {len(df)}")
        
        # MÃ©tricas principais
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_containers = df['QTDE CONTAINER'].sum()
            st.metric("Total de Containers", f"{int(total_containers):,}")
            
        with col2:
            total_clientes = df['CONSIGNATÃRIO'].nunique()
            st.metric("Total de Clientes", f"{total_clientes:,}")
            
        with col3:
            total_estados = df['UF CONSIGNATÃRIO'].nunique()
            st.metric("Estados Atendidos", total_estados)
            
        with col4:
            total_mercadorias = df['MERCADORIA'].nunique()
            st.metric("Tipos de Mercadorias", total_mercadorias)

        # AnÃ¡lise por Estado
        st.markdown("### ðŸ“ DistribuiÃ§Ã£o por Estado")
        
        # Agrupando dados por estado
        estado_data = df.groupby('UF CONSIGNATÃRIO').agg({
            'QTDE CONTAINER': 'sum',
            'CONSIGNATÃRIO': 'nunique',
            'ID_UNICO': 'count'  # Contagem de registros Ãºnicos
        }).reset_index()
        estado_data.columns = ['UF', 'Containers', 'Clientes', 'Registros']
        estado_data = estado_data.sort_values('Containers', ascending=False)

        # VisualizaÃ§Ãµes
        col1, col2 = st.columns(2)
        
        with col1:
            fig = px.bar(
                estado_data.head(10),
                x='UF',
                y='Containers',
                title='Top 10 Estados por Volume de Containers',
                color='Containers',
                color_continuous_scale='Blues'
            )
            st.plotly_chart(fig, use_container_width=True)
            
        with col2:
            fig = px.scatter(
                estado_data,
                x='Containers',
                y='Clientes',
                text='UF',
                title='RelaÃ§Ã£o entre Volume de Containers e NÃºmero de Clientes',
                size='Containers',
                color='Clientes',
                color_continuous_scale='Viridis'
            )
            st.plotly_chart(fig, use_container_width=True)

        # Timeline de chegadas
        st.markdown("### ðŸ“… Timeline de Chegadas")
        
        timeline_data = df.groupby('ETA').agg({
            'QTDE CONTAINER': 'sum',
            'CONSIGNATÃRIO': 'nunique',
            'ID_UNICO': 'count'
        }).reset_index()
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=timeline_data['ETA'],
            y=timeline_data['QTDE CONTAINER'],
            name='Containers',
            mode='lines+markers'
        ))
        fig.update_layout(title='Volume de Containers por Data de Chegada')
        st.plotly_chart(fig, use_container_width=True)

        # AnÃ¡lise de Duplicidades (para monitoramento)
        if st.sidebar.checkbox("Mostrar AnÃ¡lise de Duplicidades"):
            st.markdown("### ðŸ” AnÃ¡lise de Duplicidades")
            duplicates = df.groupby('ID_UNICO').size().reset_index(name='contagem')
            duplicates = duplicates[duplicates['contagem'] > 1]
            
            if not duplicates.empty:
                st.warning(f"Encontrados {len(duplicates)} registros com potenciais duplicidades.")
                st.dataframe(duplicates)
            else:
                st.success("Nenhuma duplicidade encontrada nos dados!")

        # RecomendaÃ§Ãµes
        st.markdown("### ðŸ“‹ RecomendaÃ§Ãµes Comerciais")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("""
            #### ðŸ”´ Prioridade Alta
            - Foco em RJ, SP e MG
            - Visitas prioritÃ¡rias aos maiores importadores
            - Desenvolver pacotes especiais para grandes volumes
            """)
            
        with col2:
            st.markdown("""
            #### ðŸŸ¡ Prioridade MÃ©dia
            - Manter relacionamento ativo
            - Identificar oportunidades de cross-selling
            - Desenvolver estratÃ©gias de crescimento
            """)
            
        with col3:
            st.markdown("""
            #### ðŸŸ¢ Prioridade Baixa
            - Monitorar mercado
            - Buscar parcerias estratÃ©gicas
            - Avaliar potencial de crescimento
            """)

    except Exception as e:
        st.error(f"Erro ao processar os dados: {str(e)}")
        st.exception(e)

if __name__ == "__main__":
    main()